{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fold Cross Validation, a good idea\n",
    "\n",
    "We already know how hard is to obtain a good dataset, a balanced one is even harder.\n",
    "\n",
    "In this article I'll explain in a pratical and simple way why fold cross validation is a good idea to further improve your ml models using the dataset you already have.\n",
    "\n",
    "For this example, let's first import one dataset and check one small sample of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)\n",
       "0                5.1               3.5                1.4\n",
       "1                4.9               3.0                1.4\n",
       "2                4.7               3.2                1.3\n",
       "3                4.6               3.1                1.5\n",
       "4                5.0               3.6                1.4"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "features_amount = 3\n",
    "dataset = {\n",
    "    \"features\": iris.data[:,:features_amount],\n",
    "    \"target\": iris.target\n",
    "}\n",
    "\n",
    "from pandas import DataFrame\n",
    "DataFrame(\n",
    "    data=dataset['features'][:5],\n",
    "    columns=iris['feature_names'][:features_amount]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, in guides/tutorials it's a common saying that the database should be splited in 80:20, 80% for training the model and 20% for testing it against. As I've done it bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = len(dataset['features'])\n",
    "eighty_percet = int(total_len*0.8)\n",
    "\n",
    "training = {\n",
    "    \"features\": dataset['features'][:eighty_percet],\n",
    "    \"target\": dataset['target'][:eighty_percet]\n",
    "}\n",
    "\n",
    "test = {\n",
    "    \"features\": dataset['features'][eighty_percet:],\n",
    "    \"target\": dataset['target'][eighty_percet:]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting, I'll use a Logistic Regression model to classify the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.7\n",
      "training score: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(training['features'], training['target'])\n",
    "\n",
    "print(f\"test score: {model.score(test['features'], test['target'])}\")\n",
    "print(f\"training score: {model.score(training['features'], training['target'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this initial split, we've got score of 70% against this testing split.\n",
    "\n",
    "But how can we know which part of the dataset would yield an better result?\n",
    "What if the first 20% features would result in a better testing split\n",
    "instead of the last 20%?\n",
    "\n",
    "To test it, there's a tecnique called **fold-cross validation**, which divide your dataset in randonly splits for the chosen size;\n",
    "\n",
    "In the test bellow, I'll make a *ten fold cross validation*, meaning that will be created unique 10 folds.\n",
    "\n",
    "I will also stores the score for later comparission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for i in range(10):\n",
    "    features_train, features_test, target_train, target_test = train_test_split(\n",
    "        dataset['features'],\n",
    "        dataset['target'],\n",
    "        train_size=0.2 # How many percents will be destined to train split\n",
    "    )\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(features_train, target_train)\n",
    "    \n",
    "    train_scores.append(model.score(features_train, target_train))\n",
    "    test_scores.append(model.score(features_test, target_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's analyze the created trained models and their scores, and check if this theory worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score = 0.9333333333333333\n",
      "test score = 0.9058333333333334\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "print(f\"train score = {mean(train_scores)}\")\n",
    "print(f\"test score = {mean(test_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for the score's mean we've got a better already result!\n",
    "\n",
    "The test score went up approximately 20% and the train score also got less overfited!\n",
    "\n",
    "But let's also check them individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test score</th>\n",
       "      <th>train score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test score  train score\n",
       "0    0.933333     0.866667\n",
       "1    0.933333     0.966667\n",
       "2    0.941667     0.966667\n",
       "3    0.858333     0.866667\n",
       "4    0.883333     0.966667\n",
       "5    0.933333     0.900000\n",
       "6    0.925000     0.966667\n",
       "7    0.850000     0.966667\n",
       "8    0.900000     0.933333\n",
       "9    0.900000     0.933333"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(data=zip(test_scores, train_scores), columns=[\"test score\", \"train score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the results were pretty good, every one of them were better them the initial %20 one, when the split were chosen whithin the dataset order.\n",
    "\n",
    "So if you are using a manual split in your models I suggest using this fold cross validation to prevent some inbalance whithin your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
